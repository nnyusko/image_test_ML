# 프로젝트 요약 (2025-09-29)

## 1. 초기 분석
- `content.txt` 파일 분석을 통해 '이상신호 감지 기반 비정상 작동 진단' 대회 목표 파악.
- `smart_ocean.ipynb`의 `RandomForest` 기반 베이스라인 코드 분석.

## 2. 모델 개발 및 실험
다양한 머신러닝 모델을 사용하여 예측 성능 개선을 시도했습니다.

### 2.1. LightGBM 모델
- `RandomForest`를 대체하여 `LightGBM` 모델을 학습하고 예측을 수행했습니다.
- **스크립트**: `smart_ocean_lightGBM.py`

### 2.2. XGBoost 모델
- 또 다른 인기 모델인 `XGBoost`를 사용하여 추가적인 예측을 수행했습니다.
- **스크립트**: `smart_ocean_xgboost.py`

### 2.3. 하이퍼파라미터 튜닝
- **GridSearchCV**: LightGBM 모델의 기본 하이퍼파라미터 튜닝을 진행했습니다.
  - **스크립트**: `smart_ocean_lightGBM_tuned.py`
- **RandomizedSearchCV**: 더 넓은 범위의 하이퍼파라미터 탐색을 위한 스크립트를 작성했습니다.
  - **스크립트**: `lgbm_random_search.py`

### 2.4. 앙상블 (Ensemble)
- 4개 모델(RandomForest, LightGBM, Tuned LightGBM, XGBoost)의 예측 결과를 종합하여 최빈값으로 투표하는 앙상블을 수행했습니다.
- **스크립트**: `ensemble.py`

## 3. 모델 성능 비교
- `train.csv` 데이터에 대한 5-Fold 교차 검증(f1-score 기준)을 통해 각 모델의 성능을 객관적으로 비교했습니다.
- **스크립트**: `compare_models.py`

**초기 교차 검증 결과:**
- **RandomForest**: 0.7714
- **LightGBM**: 0.8029
- **LightGBM_Tuned**: 0.8077
- **XGBoost**: 0.7959

## 4. 추가 실험 및 분석 (2025-09-30)
기존 모델의 성능을 더 끌어올리기 위해 다음과 같은 추가 실험을 진행했습니다.

### 4.1. RandomizedSearchCV 모델 성능 갱신
- `lgbm_random_search.py` 실행 결과, 교차 검증 F1 스코어 **0.8097**을 기록하여 가장 성능이 좋은 단일 모델로 확인되었습니다.
- **산출물**: `lgbm_random_tuned_submit.csv`

### 4.2. 피처 엔지니어링
두 가지 피처 엔지니어링 전략을 시도했으나, 단독으로는 유의미한 성능 향상을 확인하지 못했습니다.
- **행(Row) 기준 통계 피처**: 각 데이터 샘플의 통계적 특성(평균, 표준편차 등)을 피처로 추가했으나 성능 향상에 기여하지 못함 (F1: 0.8088).
- **중요 피처 기반 상호작용 피처**: 중요도 상위 피처 간의 조합 피처를 추가했으나 성능 향상 효과 미미 (F1: 0.8092).

### 4.3. 스태킹(Stacking) 앙상블
- 여러 기본 모델의 예측 결과를 메타 모델이 다시 학습하는 스태킹 앙상블을 시도했으나, 제출 결과 성능이 좋지 않았습니다.

### 4.4. 데이터 분포 분석
- `target` 변수의 클래스 분포를 확인한 결과, 21개의 모든 클래스가 **완벽하게 균일한 분포**를 보이고 있음을 발견했습니다. 데이터 불균형 문제는 성능 저하의 원인이 아닌 것으로 판명되었습니다.

### 4.5. 고급 하이퍼파라미터 튜닝 (Optuna)
- `RandomizedSearchCV` 보다 발전된 베이지안 최적화 기법을 사용하는 `Optuna` 라이브러리로 정밀 튜닝을 시도했으나, 기존 최고 성능을 넘지 못했습니다.

## 5. 최종 결론
- **최종 선택 모델**: `lgbm_random_search.py`
- **최종 제출 파일**: `lgbm_random_tuned_submit.csv` (CV F1-Score: 0.8097)

다양한 피처 엔지니어링, 앙상블, 고급 하이퍼파라미터 튜닝을 시도했으나, 현재 데이터셋에서는 **원본 데이터에 `RandomizedSearchCV`를 적용한 기본 모델**이 가장 우수한 성능을 보였습니다. 이는 추가적인 기법들이 오히려 과적합(overfitting)을 유발했거나, 데이터의 특성에 비해 과한 처리였을 가능성을 시사합니다.
