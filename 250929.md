# 프로젝트 요약 (2025-09-29)

## 1. 초기 분석
- `content.txt` 파일 분석을 통해 '이상신호 감지 기반 비정상 작동 진단' 대회 목표 파악.
- `smart_ocean.ipynb`의 `RandomForest` 기반 베이스라인 코드 분석.

## 2. 모델 개발 및 실험
다양한 머신러닝 모델을 사용하여 예측 성능 개선을 시도했습니다.

### 2.1. LightGBM 모델
- `RandomForest`를 대체하여 `LightGBM` 모델을 학습하고 예측을 수행했습니다.
- **스크립트**: `smart_ocean_lightGBM.py`
- **산출물**: `lightgbm_submit.csv`

### 2.2. XGBoost 모델
- 또 다른 인기 모델인 `XGBoost`를 사용하여 추가적인 예측을 수행했습니다.
- **스크립트**: `smart_ocean_xgboost.py`
- **산출물**: `xgboost_submit.csv`

### 2.3. 하이퍼파라미터 튜닝
- **GridSearchCV**: LightGBM 모델의 기본 하이퍼파라미터 튜닝을 진행했습니다.
  - **스크립트**: `smart_ocean_lightGBM_tuned.py`
  - **산출물**: `lgbm_tuned_submit.csv`
- **RandomizedSearchCV**: 더 넓은 범위의 하이퍼파라미터 탐색을 위한 스크립트를 작성했습니다. (시간 문제로 사용자가 직접 실행하기로 함)
  - **스크립트**: `lgbm_random_search.py`
  - **예상 산출물**: `lgbm_random_tuned_submit.csv`

### 2.4. 앙상블 (Ensemble)
- 4개 모델(RandomForest, LightGBM, Tuned LightGBM, XGBoost)의 예측 결과를 종합하여 최빈값으로 투표하는 앙상블을 수행했습니다.
- **스크립트**: `ensemble.py`
- **산출물**: `ensemble_submit.csv`

## 3. 모델 성능 비교
- `train.csv` 데이터에 대한 5-Fold 교차 검증(f1-score 기준)을 통해 각 모델의 성능을 객관적으로 비교했습니다.
- **스크립트**: `compare_models.py`
- **산출물**: `model_comparison.png` (성능 비교 시각화 그래프)

**교차 검증 결과:**
- **RandomForest**: 0.7714
- **LightGBM**: 0.8029
- **LightGBM_Tuned**: 0.8077
- **XGBoost**: 0.7959

## 4. 최종 산출물 목록

### 스크립트 파일
- `smart_ocean_lightGBM.py`
- `smart_ocean_lightGBM_tuned.py`
- `smart_ocean_xgboost.py`
- `lgbm_random_search.py`
- `ensemble.py`
- `compare_models.py`

### 제출 파일 (CSV)
- `baseline_submit.csv`
- `lightgbm_submit.csv`
- `lgbm_tuned_submit.csv`
- `xgboost_submit.csv`
- `ensemble_submit.csv`

### 기타 파일
- `assets/코드설명.md`
- `model_comparison.png`
- `250929.md` (현재 요약 파일)
